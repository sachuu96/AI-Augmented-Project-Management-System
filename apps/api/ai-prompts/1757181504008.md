can you scaffold Analytics service which is 
- Another consumer of the same events. - ProductCreated, ProductDeleted, ProductUpdated, LawStockWarning Updates aggregated stats (e.g., number of products per category, low-stock counts). keep the aggragated stats in the memory for now.
- use dynamo db for recent events and minio container to store old events. I already have kafka worker <shared woker.ts and how I use singleton producer object>
show how to wire the Analytics service with the existing producer



What I accepted
----------------
- worker thread invocation is wrapped inside publishEvent function - following decorator pattern which I accepted


what I /modified
-----------------
- offloaded aggregation functionality to a dedicated worker thread - (offload the CPU heavy analysis aggregation to a dedicated worker thread to improve the performance of the main thread. Scaffold the code for it)
- created the dynamo db table before writing if the table does not exist when starting the server
- Manually verified and updated minio accessId and accessKey
- seperate the code into two functions (to follow single responsibility concept) 
    - writing to Dynamo db functionality 
    - saving old events to S3 functionality
- Consumers are created when the server starts but producer is being created when I publish the initia event. I chose this approach because
    - consumers are ready to consume messages immediately - they are already running and can process messages as soon as they are produced
    - easier management - consumers can be managed as part of the server start up process

    BUT
     - Additional latency - when first event is published, there is an additional delay due to the creation of producer
     - May be better to go with connection pool?
